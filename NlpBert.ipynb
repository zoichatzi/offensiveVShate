{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc95e01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce GTX 1080\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "\n",
    "# If there's a GPU available\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tells PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acaa8824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "812a2fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"cleaned_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "530118a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.columns[[0]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc4ae4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class label 0 - hate speech 1 - offensive language 2 - neither"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "605e1032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data entries: 24782\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21970</th>\n",
       "      <td>1</td>\n",
       "      <td>This bitch is raising MY anxiety just by sitti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19360</th>\n",
       "      <td>1</td>\n",
       "      <td>: anxiety is such a cunt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19491</th>\n",
       "      <td>1</td>\n",
       "      <td>: \" IM CRYING that bitch going hard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class                                              tweet\n",
       "21970      1  This bitch is raising MY anxiety just by sitti...\n",
       "19360      1                           : anxiety is such a cunt\n",
       "19491      1                : \" IM CRYING that bitch going hard"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show number of data entries\n",
    "print('Number of data entries: {}'.format(len(df)))\n",
    "\n",
    "# Show a few samples\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ed4c827",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#70-30 on train and test\n",
    "df_base,df_test = train_test_split(df,\n",
    "                                   random_state = 12345, \n",
    "                                   test_size = 0.3,\n",
    "                                  stratify = df['class'])\n",
    "#90-10 on train and validation\n",
    "df_train, df_val = train_test_split(df_base, \n",
    "                                    random_state = 12345, \n",
    "                                    test_size = 0.1, \n",
    "                                    stratify = df_base['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1e2e938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (15612, 2)\n",
      "Shape: (1735, 2)\n"
     ]
    }
   ],
   "source": [
    "for item in df_train, df_val:\n",
    "    print('Shape: {}'.format(item.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5c2cff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7aca363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists for encoded text data\n",
    "def get_encoded_dict(df):\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "\n",
    "    for text in df['tweet']:\n",
    "        encoded = tokenizer.encode_plus(text,\n",
    "                                        add_special_tokens=True,\n",
    "                                        pad_to_max_length=True,\n",
    "                                        return_attention_mask=True,\n",
    "                                        max_length=64,\n",
    "                                        return_tensors='pt',\n",
    "                                        truncation=True)\n",
    "\n",
    "        input_ids.append(encoded['input_ids'])\n",
    "        attention_mask.append(encoded['attention_mask'])\n",
    "        \n",
    "    return input_ids, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "448ac675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cat lists to tensors for TensorDataset\n",
    "def get_tensors(input_ids, attention_mask):\n",
    "    \n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_mask = torch.cat(attention_mask, dim=0)\n",
    "    \n",
    "    return input_ids, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2317daef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tools for Dataloader\n",
    "from torch.utils.data import TensorDataset,DataLoader,RandomSampler,SequentialSampler\n",
    "\n",
    "# Convert df to DataLoader\n",
    "def get_dataloader(df):\n",
    "    batch_size=16\n",
    "    temp_ids, temp_masks = get_encoded_dict(df)\n",
    "    \n",
    "    # Convert to tensors\n",
    "    temp_ids, temp_masks = get_tensors(temp_ids, temp_masks)\n",
    "    temp_labels = torch.tensor(df['class'].values)\n",
    "    \n",
    "    # Generate dataset\n",
    "    temp_dataset = TensorDataset(temp_ids,\n",
    "                                 temp_masks,\n",
    "                                 temp_labels)\n",
    "    \n",
    "    # Generate dataloader\n",
    "    temp_dataloader = DataLoader(temp_dataset,\n",
    "                                 batch_size=batch_size,\n",
    "                                 sampler=RandomSampler(temp_dataset))\n",
    "    \n",
    "    return temp_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97984335",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xaris\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2226: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Get dataloader for all dataframes\n",
    "train_dataloader = get_dataloader(df_train)\n",
    "val_dataloader = get_dataloader(df_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5746ef11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',\n",
    "                                                      num_labels=3,\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n",
    "# Tell mode to use CUDA\n",
    "model.cuda()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc3b053e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring optimizer\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c41cb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Configuring scheduler\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "epochs = 2\n",
    "\n",
    "# Total steps: number of batchers * epochs\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Set up the scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps=10,\n",
    "                                            num_training_steps=total_steps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65be54f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import materics for evaluation\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63a9f5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【EPOCH: 1/ 2】\n",
      "Trainig Phase\n",
      "  Average training loss: 0.3335\n",
      "Validation Phase\n",
      "  Average validation loss: 0.2495\n",
      "  Validation accruacy: 0.9089\n",
      "\n",
      "\n",
      "【EPOCH: 2/ 2】\n",
      "Trainig Phase\n",
      "  Average training loss: 0.2246\n",
      "Validation Phase\n",
      "  Average validation loss: 0.2504\n",
      "  Validation accruacy: 0.9147\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reset history lists\n",
    "history_training_loss = []\n",
    "history_val_loss = []\n",
    "history_val_acc = []\n",
    "\n",
    "for epoch_i in range(epochs):\n",
    "    \n",
    "    print('【EPOCH: {}/ {}】'.format(epoch_i+1, epochs))\n",
    "    print('Trainig Phase')\n",
    "    \n",
    "    # Set training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Reset training loss\n",
    "    total_training_loss = 0.\n",
    "    \n",
    "    # Batch and forward\n",
    "    for batch in train_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_masks = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "    \n",
    "        # Reset gradients before \n",
    "        model.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        res = model(b_input_ids,\n",
    "                    token_type_ids=None,\n",
    "                    attention_mask=b_masks,\n",
    "                    return_dict=True,\n",
    "                    labels=b_labels)\n",
    "        \n",
    "        loss = res.loss\n",
    "        logits = res.logits\n",
    "        \n",
    "        # sumup training loss\n",
    "        total_training_loss += loss.item()\n",
    "        \n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        # update optimizer and scheduler\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "    # averrage loss\n",
    "    avg_train_loss = total_training_loss/len(train_dataloader)\n",
    "    print(\"  Average training loss: {0:.4f}\".format(avg_train_loss))\n",
    "    \n",
    "    # append the loss data to history\n",
    "    history_training_loss.append(avg_train_loss)\n",
    "    \n",
    "    # validation\n",
    "    print('Validation Phase')\n",
    "    \n",
    "    # Reset validation loss\n",
    "    total_val_loss = 0\n",
    "    \n",
    "    # Set up lists\n",
    "    ls_val_logits = []\n",
    "    ls_val_labels = []\n",
    "\n",
    "    # Get batchs from val_dataloader\n",
    "    for batch in val_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_masks = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # No need to calculate gradients\n",
    "        with torch.no_grad():\n",
    "\n",
    "            res = model(b_input_ids,\n",
    "                        token_type_ids=None,\n",
    "                        attention_mask=b_masks,\n",
    "                        labels=b_labels,\n",
    "                        return_dict=True)\n",
    "\n",
    "        val_loss = res.loss\n",
    "        val_logits = res.logits\n",
    "        total_val_loss += val_loss.item()\n",
    "\n",
    "        # Convert logitis to numpy format\n",
    "        val_logits = np.argmax(val_logits.cpu().detach().numpy(), axis=1)\n",
    "        val_labels = b_labels.cpu().detach().numpy()\n",
    "\n",
    "        # Append data to the lists\n",
    "        for logit in val_logits:\n",
    "            ls_val_logits.append(logit)\n",
    "\n",
    "        for label in val_labels:\n",
    "            ls_val_labels.append(label)\n",
    "    \n",
    "    # Get accuracy score and val_loss\n",
    "    acc = accuracy_score(ls_val_logits, ls_val_labels)\n",
    "    avg_val_loss = total_val_loss/len(val_dataloader)\n",
    "    \n",
    "    # append validation data to history\n",
    "    history_val_acc.append(acc)\n",
    "    history_val_loss.append(avg_val_loss)\n",
    "    \n",
    "    # Print out validation performance\n",
    "    print('  Average validation loss: {:.4f}'.format(avg_val_loss))\n",
    "    print('  Validation accruacy: {:.4f}'.format(acc))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ce80c3",
   "metadata": {},
   "source": [
    " \n",
    " \n",
    " \n",
    " Notice that, while the the training loss is going down with each epoch, the validation loss is increasing! This suggests that we are training our model too long, and it's over-fitting on the training data.\n",
    "\n",
    "\n",
    "Validation Loss is a more precise measure than accuracy, because with accuracy we don't care about the exact output value, but just which side of a threshold it falls on.\n",
    "\n",
    "If we are predicting the correct answer, but with less confidence, then validation loss will catch this, \n",
    "while accuracy will not.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2f5e78e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.333467</td>\n",
       "      <td>0.249527</td>\n",
       "      <td>0.908934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.224641</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.914697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  val_loss   val_acc\n",
       "0  0.333467  0.249527  0.908934\n",
       "1  0.224641  0.250400  0.914697"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert histroy to dataframe\n",
    "cols = ['loss', 'val_loss', 'val_acc']\n",
    "\n",
    "history = np.stack((\n",
    "                    np.array(history_training_loss),        \n",
    "                    np.array(history_val_loss),\n",
    "                    np.array(history_val_acc),\n",
    "                    ), axis=1)\n",
    "\n",
    "df_history = pd.DataFrame(history, columns=cols)\n",
    "\n",
    "# Show df_history\n",
    "df_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ae11f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(df_history['loss'])\n",
    "plt.plot(df_history['val_loss'])\n",
    "plt.title('loss')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(df_history['val_acc'], color='red', linestyle='--')\n",
    "plt.title('accuracy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "549036cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20287</th>\n",
       "      <td>1</td>\n",
       "      <td>: We live In a world full of unloyal hoes ugly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18216</th>\n",
       "      <td>1</td>\n",
       "      <td>: grab me some bitches while u up there lmao o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20167</th>\n",
       "      <td>1</td>\n",
       "      <td>: from tonight: \" N word or cracker. . . which...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16250</th>\n",
       "      <td>1</td>\n",
       "      <td>: Let me make this clear I don't need no fucki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14276</th>\n",
       "      <td>1</td>\n",
       "      <td>: ELI Manning is fucking trash rap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20502</th>\n",
       "      <td>1</td>\n",
       "      <td>Really. 3 hours to find paper work is retarded...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16686</th>\n",
       "      <td>1</td>\n",
       "      <td>: just knowing U can still go out and bag some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4377</th>\n",
       "      <td>0</td>\n",
       "      <td>it was Paul McCartney faggot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6200</th>\n",
       "      <td>1</td>\n",
       "      <td>do it you pussy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4746</th>\n",
       "      <td>1</td>\n",
       "      <td>what u doing bitch boy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7435 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       class                                              tweet\n",
       "20287      1  : We live In a world full of unloyal hoes ugly...\n",
       "18216      1  : grab me some bitches while u up there lmao o...\n",
       "20167      1  : from tonight: \" N word or cracker. . . which...\n",
       "16250      1  : Let me make this clear I don't need no fucki...\n",
       "14276      1                 : ELI Manning is fucking trash rap\n",
       "...      ...                                                ...\n",
       "20502      1  Really. 3 hours to find paper work is retarded...\n",
       "16686      1  : just knowing U can still go out and bag some...\n",
       "4377       0                       it was Paul McCartney faggot\n",
       "6200       1                                    do it you pussy\n",
       "4746       1                             what u doing bitch boy\n",
       "\n",
       "[7435 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4567c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xaris\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='class', ylabel='count'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEJCAYAAABlmAtYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAASsUlEQVR4nO3df6zd9X3f8ecrJqV0DQoUw1zbqUnnZbNp04wrxIY0dbAN71dA0YgcNcXqUN0hmhBpP2qqrcm6WYvUrFpAAclaE9tdWmaRdHhVaMa8pFkyArlOSYztMKxA4c4ONmQVZupY7L33x/mgnNjX93MMPuf4cp8P6avz/b7P9/M976Mj+6Xvz5uqQpKkhbxp2g1Iks5/hoUkqcuwkCR1GRaSpC7DQpLUZVhIkrrGGhZJ3prkgSTfSnIwyV9OcmmSh5M81V4vGVr/riSHkjyZ5Mah+tVJ9rX37k6ScfYtSfpB496z+DjwB1X1F4B3AgeBLcCeqloL7GnLJFkHbATWAxuAe5Msa9u5D9gMrG3ThjH3LUkaknHdlJfkYuAbwNtr6EOSPAn8bFUdSbIC+GJVvSPJXQBV9a/bep8HPgI8A3yhBQ5J3tfG/9JCn3/ZZZfVmjVrzvn3kqQ3sr17975QVctPrV8wxs98O3AM+FSSdwJ7gTuBK6rqCEALjMvb+iuBrw6Nn2u177X5U+sLWrNmDbOzs6/7S0jSUpLkj+erj/Mw1AXAXwLuq6p3Af+bdsjpDOY7D1EL1E/fQLI5yWyS2WPHjp1tv5KkMxhnWMwBc1X1aFt+gEF4PN8OP9Fejw6tv3po/CrgcKuvmqd+mqraVlUzVTWzfPlpe1GSpNdobGFRVd8Bnkvyjla6ATgA7AY2tdom4ME2vxvYmOTCJFcyOJH9WDtkdTzJte0qqFuHxkiSJmCc5ywAPgB8OskPAd8GfoFBQO1KchvwLHALQFXtT7KLQaCcAO6oqpNtO7cD24GLgIfaJEmakLFdDTVtMzMz5QluSTo7SfZW1cypde/gliR1GRaSpC7DQpLUZVhIkrrGfTWUNFbP/vpPTbuFJeFtv7Zv2i1oytyzkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6hprWCR5Jsm+JI8nmW21S5M8nOSp9nrJ0Pp3JTmU5MkkNw7Vr27bOZTk7iQZZ9+SpB80iT2Lv1ZVP1NVM215C7CnqtYCe9oySdYBG4H1wAbg3iTL2pj7gM3A2jZtmEDfkqRmGoehbgJ2tPkdwM1D9fur6pWqeho4BFyTZAVwcVU9UlUF7BwaI0magHGHRQH/OcneJJtb7YqqOgLQXi9v9ZXAc0Nj51ptZZs/tS5JmpALxrz966rqcJLLgYeTfGuBdec7D1EL1E/fwCCQNgO87W1vO9teJUlnMNY9i6o63F6PAr8HXAM83w4t0V6PttXngNVDw1cBh1t91Tz1+T5vW1XNVNXM8uXLz+VXkaQlbWxhkeTPJHnLq/PA3wSeAHYDm9pqm4AH2/xuYGOSC5NcyeBE9mPtUNXxJNe2q6BuHRojSZqAcR6GugL4vXaV6wXA71TVHyT5GrAryW3As8AtAFW1P8ku4ABwArijqk62bd0ObAcuAh5qkyRpQsYWFlX1beCd89RfBG44w5itwNZ56rPAVee6R0nSaLyDW5LUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lS19jDIsmyJH+U5Pfb8qVJHk7yVHu9ZGjdu5IcSvJkkhuH6lcn2dfeuztJxt23JOn7JrFncSdwcGh5C7CnqtYCe9oySdYBG4H1wAbg3iTL2pj7gM3A2jZtmEDfkqRmrGGRZBXwd4B/N1S+CdjR5ncANw/V76+qV6rqaeAQcE2SFcDFVfVIVRWwc2iMJGkCxr1n8W+Bfwr8v6HaFVV1BKC9Xt7qK4Hnhtaba7WVbf7UuiRpQsYWFkn+LnC0qvaOOmSeWi1Qn+8zNyeZTTJ77NixET9WktQzzj2L64B3J3kGuB+4Psm/B55vh5Zor0fb+nPA6qHxq4DDrb5qnvppqmpbVc1U1czy5cvP5XeRpCVtbGFRVXdV1aqqWsPgxPV/rar3A7uBTW21TcCDbX43sDHJhUmuZHAi+7F2qOp4kmvbVVC3Do2RJE3ABVP4zI8Cu5LcBjwL3AJQVfuT7AIOACeAO6rqZBtzO7AduAh4qE2SpAmZSFhU1ReBL7b5F4EbzrDeVmDrPPVZ4KrxdShJWoh3cEuSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUtdIYZFkzyg1SdIb04J/gzvJDwM/AlyW5BIg7a2LgR8fc2+SpPPEgmEB/BLwIQbBsJfvh8VLwCfG15Yk6XyyYFhU1ceBjyf5QFXdM6GeJEnnmd6eBQBVdU+SvwKsGR5TVTvH1Jck6TwyUlgk+W3gJ4HHgZOtXIBhIUlLwEhhAcwA66qqxtmMJOn8NOp9Fk8Af3acjUiSzl+j7llcBhxI8hjwyqvFqnr3WLqSJJ1XRg2Lj5zthts9Gl8CLmyf80BVfTjJpcB/YHCy/BngvVX1v9qYu4DbGJwX+WBVfb7Vrwa2AxcBnwPu9JCYJE3OqFdD/eFr2PYrwPVV9XKSNwNfTvIQ8B5gT1V9NMkWYAvwK0nWARuB9Qzu6/gvSf58VZ0E7gM2A19lEBYbgIdeQ0+SpNdg1Md9HE/yUpv+T5KTSV5aaEwNvNwW39ymAm4CdrT6DuDmNn8TcH9VvVJVTwOHgGuSrAAurqpH2t7EzqExkqQJGHXP4i3Dy0luBq7pjUuyjMGd338O+ERVPZrkiqo60rZ7JMnlbfWVDPYcXjXXat9r86fWJUkT8pqeOltV/xG4foT1TlbVzwCrGOwlXLXA6pmnVgvUT99AsjnJbJLZY8eO9dqTJI1o1Jvy3jO0+CYG912MfIK5qv4kyRcZnGt4PsmKtlexAjjaVpsDVg8NWwUcbvVV89Tn+5xtwDaAmZkZT4BL0jky6p7F3xuabgSOMzjHcEZJlid5a5u/CPjrwLeA3cCmttom4ME2vxvYmOTCJFcCa4HH2iGr40muTRLg1qExkqQJGPWcxS+8hm2vAHa08xZvAnZV1e8neQTYleQ24FnglvYZ+5PsAg4AJ4A72pVQALfz/UtnH8IroSRpokY9DLUKuAe4jsHhpy8zuNdh7kxjquqbwLvmqb8I3HCGMVuBrfPUZ4GFzndIksZo1MNQn2JwmOjHGVyJ9J9aTZK0BIwaFsur6lNVdaJN24HlY+xLknQeGTUsXkjy/iTL2vR+4MVxNiZJOn+MGhb/AHgv8B3gCPD3gddy0luStAiN+iDBfwlsGnrg36XAxxiEiCTpDW7UPYuffjUoAKrqu8xzpZMk6Y1p1LB4U5JLXl1oexaj7pVIkha5Uf/D/zfAf0/yAIP7LN7LPPdDSJLemEa9g3tnklkGDw8M8J6qOjDWziRJ542RDyW1cDAgJGkJek2PKJckLS2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXWMLiySrk3whycEk+5Pc2eqXJnk4yVPt9ZKhMXclOZTkySQ3DtWvTrKvvXd3koyrb0nS6ca5Z3EC+EdV9ReBa4E7kqwDtgB7qmotsKct097bCKwHNgD3JlnWtnUfsBlY26YNY+xbknSKsYVFVR2pqq+3+ePAQWAlcBOwo622A7i5zd8E3F9Vr1TV08Ah4JokK4CLq+qRqipg59AYSdIETOScRZI1wLuAR4ErquoIDAIFuLytthJ4bmjYXKutbPOn1iVJEzL2sEjyo8BngA9V1UsLrTpPrRaoz/dZm5PMJpk9duzY2TcrSZrXWMMiyZsZBMWnq+qzrfx8O7REez3a6nPA6qHhq4DDrb5qnvppqmpbVc1U1czy5cvP3ReRpCVunFdDBfgt4GBV/ebQW7uBTW1+E/DgUH1jkguTXMngRPZj7VDV8STXtm3eOjRGkjQBF4xx29cBPw/sS/J4q/0q8FFgV5LbgGeBWwCqan+SXcABBldS3VFVJ9u424HtwEXAQ22SJE3I2MKiqr7M/OcbAG44w5itwNZ56rPAVeeuO0nS2fAObklSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpK4Lpt2ApKXrunuum3YLb3hf+cBXzsl23LOQJHUZFpKkLsNCktRlWEiSusYWFkk+meRokieGapcmeTjJU+31kqH37kpyKMmTSW4cql+dZF977+4kGVfPkqT5jXPPYjuw4ZTaFmBPVa0F9rRlkqwDNgLr25h7kyxrY+4DNgNr23TqNiVJYza2sKiqLwHfPaV8E7Cjze8Abh6q319Vr1TV08Ah4JokK4CLq+qRqipg59AYSdKETPqcxRVVdQSgvV7e6iuB54bWm2u1lW3+1LokaYLOlxPc852HqAXq828k2ZxkNsnssWPHzllzkrTUTTosnm+HlmivR1t9Dlg9tN4q4HCrr5qnPq+q2lZVM1U1s3z58nPauCQtZZMOi93Apja/CXhwqL4xyYVJrmRwIvuxdqjqeJJr21VQtw6NkSRNyNieDZXkd4GfBS5LMgd8GPgosCvJbcCzwC0AVbU/yS7gAHACuKOqTrZN3c7gyqqLgIfaJEmaoLGFRVW97wxv3XCG9bcCW+epzwJXncPWJEln6Xw5wS1JOo8ZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXWP7exaLydX/ZOe0W3jD2/sbt067BUmvg3sWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSuhZNWCTZkOTJJIeSbJl2P5K0lCyKsEiyDPgE8LeAdcD7kqybbleStHQsirAArgEOVdW3q+r/AvcDN025J0laMhZLWKwEnhtanms1SdIELJa/Z5F5anXaSslmYHNbfDnJk2PtarouA16YdhOjysc2TbuF88mi+u0A+PB8/wSXrEX1++WDZ/3b/cR8xcUSFnPA6qHlVcDhU1eqqm3Atkk1NU1JZqtqZtp96Oz52y1uS/X3WyyHob4GrE1yZZIfAjYCu6fckyQtGYtiz6KqTiT5ZeDzwDLgk1W1f8ptSdKSsSjCAqCqPgd8btp9nEeWxOG2Nyh/u8VtSf5+qTrtPLEkST9gsZyzkCRNkWGxyPjYk8UrySeTHE3yxLR70dlJsjrJF5IcTLI/yZ3T7mnSPAy1iLTHnvwP4G8wuJz4a8D7qurAVBvTSJL8VeBlYGdVXTXtfjS6JCuAFVX19SRvAfYCNy+lf3vuWSwuPvZkEauqLwHfnXYfOntVdaSqvt7mjwMHWWJPkTAsFhcfeyJNWZI1wLuAR6fcykQZFovLSI89kTQeSX4U+Azwoap6adr9TJJhsbiM9NgTSedekjczCIpPV9Vnp93PpBkWi4uPPZGmIEmA3wIOVtVvTrufaTAsFpGqOgG8+tiTg8AuH3uyeCT5XeAR4B1J5pLcNu2eNLLrgJ8Hrk/yeJv+9rSbmiQvnZUkdblnIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCGoMkH0nyj6fdh3SuGBaSpC7DQjoHktya5JtJvpHkt0957xeTfK2995kkP9LqtyR5otW/1GrrkzzWbvr6ZpK10/g+0qm8KU96nZKsBz4LXFdVLyS5FPgg8HJVfSzJj1XVi23dfwU8X1X3JNkHbKiq/5nkrVX1J0nuAb5aVZ9uj3RZVlV/Oq3vJr3KPQvp9bseeKCqXgCoqlP/ZsVVSf5bC4efA9a3+leA7Ul+EVjWao8Av5rkV4CfMCh0vjAspNcvLPyo+O3AL1fVTwH/AvhhgKr6h8A/Y/Ak4cfbHsjvAO8G/hT4fJLrx9m4NCrDQnr99gDvTfJjAO0w1LC3AEfaI65/7tVikp+sqker6teAF4DVSd4OfLuq7mbwROGfnsg3kDoumHYD0mJXVfuTbAX+MMlJ4I+AZ4ZW+ecM/qraHwP7GIQHwG+0E9hhEDjfALYA70/yPeA7wK9P5EtIHZ7gliR1eRhKktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpK7/Dw4oLMfm84abAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(df_test['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f551e8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xaris\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2226: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches in the dataloader: 233\n"
     ]
    }
   ],
   "source": [
    "# Prepare df_test for prediction\n",
    "t_input_ids, t_attention_mask = get_encoded_dict(df_test)\n",
    "t_input_ids, t_attention_mask = get_tensors(t_input_ids, t_attention_mask)\n",
    "\n",
    "# Prepare dataset and dataloader\n",
    "test_dataset = TensorDataset(t_input_ids, t_attention_mask)\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "                             batch_size=32,\n",
    "                             sampler=SequentialSampler(test_dataset))\n",
    "\n",
    "# Show dataloader length\n",
    "print('Number of batches in the dataloader: {}'.format(len(test_dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed6d36e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7435\n"
     ]
    }
   ],
   "source": [
    "# Setup lists for predictions and labels\n",
    "ls_test_pred = []\n",
    "\n",
    "# Get batchs from test_dataloader\n",
    "for batch in test_dataloader:\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_masks = batch[1].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        res = model(b_input_ids,\n",
    "                    attention_mask=b_masks,\n",
    "                    return_dict=True)\n",
    "\n",
    "        test_logits = res.logits\n",
    "        test_logits = np.argmax(test_logits.cpu().detach().numpy(), axis=1)\n",
    "        \n",
    "        for pred in test_logits:\n",
    "            ls_test_pred.append(pred)\n",
    "            \n",
    "print(len(ls_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a0b5d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy: 0.9131\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Set up list of test labels\n",
    "ls_test_labels = list(df_test['class'].values)\n",
    "\n",
    "# Get accuracy score and val_loss\n",
    "acc = accuracy_score(ls_test_pred, ls_test_labels)\n",
    "print('Prediction accuracy: {:.4f}'.format(acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb5b97eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(ls_test_pred, ls_test_labels)\n",
    "\n",
    "sns.heatmap(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2839be7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.52      0.41       279\n",
      "           1       0.95      0.94      0.95      5839\n",
      "           2       0.92      0.87      0.89      1317\n",
      "\n",
      "    accuracy                           0.91      7435\n",
      "   macro avg       0.74      0.78      0.75      7435\n",
      "weighted avg       0.93      0.91      0.92      7435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "cr = classification_report(ls_test_pred, ls_test_labels)\n",
    "\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b94bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
